---
title: "About Ai"
date: 2025-08-03T10:15:13+02:00
draft: true
type: "blog"
tags: ["ai"]
cover:
  image: "images/gradient.png"
toc: true
description: "About ai"
---
For the last 1.5 years, I have forced myself to work with and learn AI, mostly because the future of software engineering will inevitably have more AI within it. I've focused on optimizing my workflow to understand when AI is a genuinely useful tool versus when it's a hindrance. Now, 1.5 years later, I feel confident enough to say I've learned enough about AI to have some strong opinions, which is why I'm writing this post.

There's a strange disconnect in the industry. On one hand, [GitHub](https://fortune.com/2024/10/30/googles-code-ai-sundar-pichai/) claims that 20 million users are on Copilot, and [Sundar Pichai](https://techcrunch.com/2025/07/30/github-copilot-crosses-20-million-all-time-users/) says that over 25% of the code at Google is now written by AI. On the other hand, [independent studies](https://www.reuters.com/business/ai-slows-down-some-experienced-software-developers-study-finds-2025-07-10/) show that AI actually makes experienced developers slower. The common thread seems to be that the companies selling an AI solution advocate for its efficiency, while independent sources tell a different story. It's also incredibly difficult to measure AI's true efficiency. Most metrics focus on whether we accept an AI's suggestion, not on whether we accept that code, leave it unedited, and ship it to productionâ€”mostly because tracking that is a profoundly difficult task.

My experience lands somewhere in the middle. I've learned that AI is phenomenally good at helping me with all the "bullshit code": refactoring, simple tasks that take two minutes to develop, or analyzing a piece of code. But for anything else, AI is mostly in my way, especially when developing something new. The reason is that AI can lure you down a deep rabbit hole of bad abstractions that can take a significant amount of time to fix. I've learned that you must understand in detail how you want to solve a problem to even have a fair shot at AI helping you. When a task is more than just busywork, AI gets in the way. The many times I've let AI do most of the job, I've been left with more bugs and poorly considered details in the implementation. Programming is the type of work where there often is no obvious solution; we need to "feel" the code as we work with it to truly understand the problem.

When I work on something I've never worked on before, AI is a nice tool to get some kind of direction. Sometimes this direction is really good, and sometimes it's horrible and makes me lose a day or two of work. It's a gamble, but the more experienced you become, the easier it is to know when you're going in the wrong direction.

But I am optimistic. I do think we can have a beautiful future where engineers and AI can work side-by-side together and create cool stuff.

I've used IDEs, chat interfaces, web interfaces like Lovable, and CLIs, and it's with CLIs that I've gained the most value. So far, CLIs are the best way to work with AI because you have full control over the context, and you are forced to think through the solution before you hit enter. In contrast, IDEs often suggest code and make changes automatically, sometimes without my full awareness. In a way, CLIs keep me in the loop as an active participant, not a passive observer.

For everything I don't like doing, AI is phenomenally good. Take design, for instance. I've used Lovable and Figma to generate beautiful UIs and then copied the HTML to implement in an Elixir dashboard, and the results have been stunning. I also use AI when I write articles to help with spelling and maintaining a clear narrative thread. It's rare, but sometimes you get lucky and the AI handles a simple task for you perfectly.

## Good stuff
## Vibe coding
## Tech debt
## We don't become more efficient
## The gainer of AI is not the developers, is the people around
